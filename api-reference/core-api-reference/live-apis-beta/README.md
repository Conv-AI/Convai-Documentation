---
description: >-
  Enable real-time, low-latency interaction with Convai AI characters through
  WebRTC-based Live APIs that support text, audio, and dynamic contextual
  communication.
metaLinks:
  alternates:
    - >-
      https://app.gitbook.com/s/EtUJA212Zc1S9ACc8T4l/api-reference/core-api-reference/live-apis-beta
---

# Live APIs (Beta)

Convai’s **Live APIs** enable real-time, dynamic interaction between users and AI characters through **WebRTC**.\
These APIs allow your applications to send and receive **audio**, **text**, and other contextual data, making conversations with AI characters seamless and responsive.

Once your characters are created, the Live APIs manage conversational input and contextual responses automatically, ensuring natural and consistent behavior across sessions.

#### **With the Live APIs, you can:**

* **Engage in live conversations** — Send user text or voice inputs and receive contextual, natural replies in real time.
* **Retrieve responses in text and/or audio form** — Power both text-based chat and voice dialogue experiences.
* **Use realtime models** — Integrate with low-latency models (currently Google Realtime; OpenAI support coming soon) for high-speed conversational performance.

The **Live APIs** act as the bridge between your AI characters and users, enabling smooth, two-way communication across both **text** and **voice** channels — all in real time.
